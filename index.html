---
layout: default
---

<body>
  <h1 style="margin-top: 0px">Index</h1>
  {% assign sorted_posts = site.posts | sort:'title' %}
  {% for post in sorted_posts %}
  <div class="postpreview">
    <div class="category">
      ({{ post.categories | first }}) <span class="year">[{{ post.year }}]</span>
    </div>
    <img src="{{ post.thumb | relative_url }}"></img>
    <div class="title">
      <a href="{{ post.url | relative_url }}">{{ post.title | truncate: 70}}</a>
    </div>
  </div>  
  {% endfor %}

  <div style="clear: both;"></div>


  <h1 style="margin-top: 35px">To Read</h1>
  <a href="https://arxiv.org/abs/1802.05751">Image Transformer</a>
  <br><a href="https://arxiv.org/pdf/1905.07478.pdf">Dueling Decoders: Regularizing Variational Autoencoder Latent Spaces</a>
  <br><a href="https://arxiv.org/pdf/1705.03122.pdf">Convolutional Sequence to Sequence Learning</a>
  <br><a href="https://arxiv.org/pdf/1802.06869.pdf">Invertible Autoencoder for domain adaptation</a>
  <br><a href="https://openreview.net/pdf?id=ByN7Yo05YX">Adaptive Neural Trees</a>
  <br><a href="https://www.sciencedirect.com/science/article/pii/S2352154618301943">Reconciling deep learning with symbolic artificial intelligence: representing objects and relations</a>
  <br><a href="https://arxiv.org/pdf/1102.1808.pdf">From Machine Learning to Machine Reasoning</a>
  <br><a href="https://openreview.net/pdf?id=HymuJz-A-">Not-So-CLEVR: Visual relations Strain Feed-forward Neural Networks</a>
  <br><a href="https://arxiv.org/pdf/1802.02745.pdf">Learning Inductive Biases with Simple Neural Networks</a>
  <br><a href="https://arxiv.org/abs/1903.01069">Do Neural Networks Show Gestalt Phenomena ?</a>
  <br><a href="https://openreview.net/pdf?id=SyNPk2R9K7">Learning to describe scenes with programs</a>
  <br><a href="https://www.automl.org/wp-content/uploads/2018/12/metalearning.pdf">Meta-Learning Tutorial</a>
  <br><a href="https://arxiv.org/pdf/1811.07441.pdf">Learning to Generate the “Unseen” via Part Synthesis and Composition</a>
  <br><a href="https://arxiv.org/pdf/1810.00597.pdf">Taming VAEs</a>
  <br><a href="https://openreview.net/pdf?id=rJgP7hR5YQ">Composition and Decomposition of GANs</a>
  <br><a href="https://arxiv.org/pdf/1805.04833.pdf">Hierarchical Neural Story Generation</a>
  <br><a href="https://arxiv.org/pdf/1811.11606.pdf">Escaping Plato’s Cave using Adversarial Training: 3D Shape From Unstructured 2D Image Collections</a>
  <br><a href="https://arxiv.org/pdf/1904.04744.pdf">Learning Across Tasks and Domains</a>
  <br><a href="https://arxiv.org/pdf/1904.04402.pdf">Towards Universal Object Detection by Domain Attention</a>
  <br><a href="https://arxiv.org/pdf/1901.11399.pdf">Equivariant Transformer Networks</a>
  <br><a href="https://openreview.net/pdf?id=r1lWUoA9FQ">Are Adversariable Examples Inevitable ?</a>
  <br><a href="https://openreview.net/pdf?id=SyzVb3CcFX">Time Agnostic Predictions: Predicting Predictable Video Frames</a>
  <br><a href="https://arxiv.org/abs/1707.08139">Analogs of Linguistic Structure in Deep Representations</a>
  <br><a href="">Copy the Old or Paint Anew? An Adversarial Framework for (non-) Parametric Image Stylization</a>
  <br><a href="">Partial Transfer Learning with Selective Adversarial Networks</a>
</body>
